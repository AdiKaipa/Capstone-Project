{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generation of Code using Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb53921547c3412281a8e3e2b22adfe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d149138aff6460e8be2f151efe60ba1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_98a9bf85310a4648a03ed01bf0d640e3",
              "IPY_MODEL_dfa6526c89f0459cb36e1abb1b128b74"
            ]
          }
        },
        "7d149138aff6460e8be2f151efe60ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98a9bf85310a4648a03ed01bf0d640e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_61a79a10db8b4e109c3b0da5d652432e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4505,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4505,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ed43e52fcd44adaadb3dd7b0c1befdb"
          }
        },
        "dfa6526c89f0459cb36e1abb1b128b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1edbc118d80b4f2d81b3895f0762b481",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4505/4505 [00:00&lt;00:00, 90006.52it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03be22ac73b64fdfa2f528f5c033c732"
          }
        },
        "61a79a10db8b4e109c3b0da5d652432e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ed43e52fcd44adaadb3dd7b0c1befdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1edbc118d80b4f2d81b3895f0762b481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03be22ac73b64fdfa2f528f5c033c732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdiKaipa/Capstone-Project/blob/main/Generation_of_Code_using_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8e8dP4MletJ"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AG8xqZ5SiMD"
      },
      "source": [
        "import string\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "\r\n",
        "import torchtext\r\n",
        "from torchtext import legacy\r\n",
        "from torchtext.legacy.data import Field, BucketIterator\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6GDjRe3K8J5"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbFFaWd3OhqC",
        "outputId": "233f1bc7-d57a-4c5f-d72c-107569467a8e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inXDAB1pTl-O"
      },
      "source": [
        "path = '/content/drive/MyDrive/END/Capstone Project/English_Python_Data_Latest.txt'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy23AWi9lo20"
      },
      "source": [
        "#Reading data from the text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGlDnIBTzUz"
      },
      "source": [
        "def Read_Text(file_name):\r\n",
        "  file = open(file_name, mode = 'rt', encoding= 'utf-8')\r\n",
        "  text = file.read()\r\n",
        "  file.close()\r\n",
        "  return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3JetYsdUOya"
      },
      "source": [
        "data_text = Read_Text(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "5AUBIGZrUVWL",
        "outputId": "fc3872fc-a405-4297-eab1-e5c4b56ada8a"
      },
      "source": [
        "data_text[:1000]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"# write a python program to add two numbers \\nnum1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\nprint(f'Sum: {sum}')\\n\\n\\n# write a python function to add two user provided numbers and return the sum\\ndef add_two_numbers(num1, num2):\\n    sum = num1 + num2\\n    return sum\\n\\n\\n# write a program to find and print the largest among three numbers\\n\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >= num2) and (num1 >= num3):\\n   largest = num1\\nelif (num2 >= num1) and (num2 >= num3):\\n   largest = num2\\nelse:\\n   largest = num3\\nprint(f'largest:{largest}')\\n\\n\\n# write a program to find and print the smallest among three numbers\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= num2) and (num1 <= num3):\\n   smallest = num1\\nelif (num2 <= num1) and (num2 <= num3):\\n   smallest = num2\\nelse:\\n   smallest = num3\\nprint(f'smallest:{smallest}')\\n\\n\\n# Write a python function to merge two given lists into one\\ndef merge_lists(l1, l2):\\n    return l1 + l2\\n\\n\\n# Write a program to check whether a number is prime or not\\nnum = 337\\n\\nif num > 1:\\n   for i in ra\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClD35ngUlyJf"
      },
      "source": [
        "#PreProcessing of the Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y86nnMEAUlV6"
      },
      "source": [
        "def Special_char_space(data):\r\n",
        "  data = data.lower()\r\n",
        "  data = data.replace(':', ' : ')\r\n",
        "  data = data.replace('=', ' = ')\r\n",
        "  data = data.replace('(', ' ( ')\r\n",
        "  data = data.replace(')', ' ) ')\r\n",
        "  data = data.replace('\\n\\n\\n', '\\n')\r\n",
        "  return data \r\n",
        "data_text = Special_char_space(data_text)\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohe-8mUJDVY2"
      },
      "source": [
        "def PreProcess(data):\r\n",
        "  data_latest = re.sub(r'#[0-9]', '#', data)\r\n",
        "  data_latest = re.sub(r'#[0-9.]', '#', data_latest)\r\n",
        "  data_latest = re.sub(r'# ', '#', data_latest)\r\n",
        "  data_latest = re.sub(r'    ', '\\t', data_latest)\r\n",
        "  return data_latest\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z4jZ5B6EpSS"
      },
      "source": [
        "data_latest = PreProcess(data_text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vC_rxNTkFAJC",
        "outputId": "916bd425-2231-44f3-f732-267fb5791fe3"
      },
      "source": [
        "data_latest[:100]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"#write a python program to add two numbers \\nnum1  =  1.5\\nnum2  =  6.3\\nsum  =  num1 + num2\\nprint ( f'\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA05_durl8hK"
      },
      "source": [
        "# DataFrame creation with Title and Target Code as Columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOqE_izzv451"
      },
      "source": [
        "sent = data_latest.split('#')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9q0F_ZSwjZ-",
        "outputId": "e4bd44a4-56f2-4565-e888-9f414201ace8"
      },
      "source": [
        "len(sent)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiInp-z70ye-",
        "outputId": "fdbc4e16-b721-4a72-f7a0-ce34d67a420a"
      },
      "source": [
        "sent[:100]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " \"write a python program to add two numbers \\nnum1  =  1.5\\nnum2  =  6.3\\nsum  =  num1 + num2\\nprint ( f'sum :  {sum}' ) \\n\",\n",
              " 'write a python function to add two user provided numbers and return the sum\\ndef add_two_numbers ( num1, num2 )  : \\n\\tsum  =  num1 + num2\\n\\treturn sum\\n',\n",
              " \"write a program to find and print the largest among three numbers\\n\\nnum1  =  10\\nnum2  =  12\\nnum3  =  14\\nif  ( num1 > =  num2 )  and  ( num1 > =  num3 )  : \\n   largest  =  num1\\nelif  ( num2 > =  num1 )  and  ( num2 > =  num3 )  : \\n   largest  =  num2\\nelse : \\n   largest  =  num3\\nprint ( f'largest : {largest}' ) \\n\",\n",
              " \"write a program to find and print the smallest among three numbers\\nnum1  =  10\\nnum2  =  12\\nnum3  =  14\\nif  ( num1 < =  num2 )  and  ( num1 < =  num3 )  : \\n   smallest  =  num1\\nelif  ( num2 < =  num1 )  and  ( num2 < =  num3 )  : \\n   smallest  =  num2\\nelse : \\n   smallest  =  num3\\nprint ( f'smallest : {smallest}' ) \\n\",\n",
              " 'write a python function to merge two given lists into one\\ndef merge_lists ( l1, l2 )  : \\n\\treturn l1 + l2\\n',\n",
              " 'write a program to check whether a number is prime or not\\nnum  =  337\\n\\nif num > 1 : \\n   for i in range ( 2, num//2 + 1 )  : \\n\\t   if  ( num % i )   =  =  0 : \\n\\t\\t   print ( num,\"is not a prime number\" ) \\n\\t\\t   print ( f\"{i} times {num//i} is {num}\" ) \\n\\t\\t   break\\n   else : \\n\\t   print ( f\"{num} is a prime number\" ) \\n\\nelse : \\n   print ( f\"{num} is not a prime number\" ) \\n',\n",
              " 'write a python function that prints the factors of a given number\\ndef print_factors ( x )  : \\n   print ( f\"the factors of {x} are : \" ) \\n   for i in range ( 1, x + 1 )  : \\n\\t   if x % i  =  =  0 : \\n\\t\\t   print ( i ) \\n\\n',\n",
              " 'write a program to find the factorial of a number\\nnum  =  13\\nfactorial  =  1\\n\\nif num < 0 : \\n   print ( \"no factorials for negative numbers!\" ) \\n\\nelif num  =  =  0 : \\n   print ( \"the factorial of 0 is 1\" ) \\n\\nelse : \\n   for i in range ( 1,num + 1 )  : \\n\\t   factorial  =  factorial*i\\n   print ( f\"the factorial of {num} is {factorial}\" ) \\n',\n",
              " 'write a python function to print whether a number is negative, positive or zero\\ndef check_pnz ( num )  : \\n\\tif num > 0 : \\n\\t   print ( \"positive number\" ) \\n\\n\\telif num  =  =  0 : \\n\\t   print ( \"zero\" ) \\n\\n\\telse : \\n\\t   print ( \"negative number\" ) \\n',\n",
              " 'write a program to print the multiplication table of a given number\\n\\nnum  =  9\\nfor i in range ( 1, 11 )  : \\n   print ( f\"{num} x {i}  =  {num*i}\" ) \\n',\n",
              " 'write a python function to print powers of 2, for given number of terms\\ndef two_power ( terms )  : \\n\\tresult  =  list ( map ( lambda x :  2 ** x, range ( terms )  )  ) \\n\\n\\tprint ( f\"the total terms are :  {terms}\" ) \\n\\tfor i in range ( terms )  : \\n\\t   print ( f\"2^{i}  =  {result[i]}\" ) \\n',\n",
              " 'write a program to filter the numbers in a list which are divisible by a given number\\nmy_list  =  [11, 45, 74, 89, 132, 239, 721, 21]\\n\\nnum  =  3\\nresult  =  list ( filter ( lambda x :   ( x % num  =  =  0 ) , my_list )  ) \\n\\nprint ( f\"numbers divisible by {num} are {result}\" ) \\n',\n",
              " 'write a python function that returns the sum of n natural numbers\\ndef sum_natural ( num )  : \\n\\tif num < 0 : \\n\\t   print ( \"please enter a positive number!\" ) \\n\\telse : \\n\\t   sum  =  0\\n\\t   while ( num > 0 )  : \\n\\t\\t   sum + =  num\\n\\t\\t   num - =  1\\n\\t   return num\\n\\n',\n",
              " 'write a program to swap first and last elements in a list\\nmy_list  =  [1, 2, 3, 4, 5, 6]\\nmy_list[0], my_list[-1]  =  my_list[-1], my_list[0]\\n',\n",
              " 'write a python function to find the area of a circle, whose radius is given\\ndef findarea ( r )  :  \\n\\tpi  =  3.142\\n\\treturn pi *  ( r*r ) \\n',\n",
              " 'write a program to print the sum of squares of first n natural numbers\\nn  =  21\\nsum_n  =  0\\nfor i in range ( 1, n+1 )  : \\n\\tsum_n + =  i**2\\nprint ( sum_n ) \\n',\n",
              " 'write a program to print the length of a list\\nmy_list  =  [1, 2, 3, 4, 5, 6, 7, 8, 9]\\n\\nprint ( len ( my_list )  ) \\n',\n",
              " 'write a pythno function to print the length of a given tuple\\nmy_tuple  =   ( 1, 2, 3, 4, 5, 6, 7, 8 ) \\n\\nprint ( len ( my_tuple )  ) \\n',\n",
              " 'write a python function to print the elements of a given list, one element in a line\\ndef custom_print ( l )  : \\n\\tfor _ in l : \\n\\t\\tprint ( _ ) \\n',\n",
              " 'write a python function to remove all the odd numbers from a list and return the remaining list\\n\\ndef remove_odd ( my_list )  : \\n\\tresult  =  list ( filter ( lambda x :   ( x % 2  =  =  0 ) , my_list )  ) \\n\\treturn result\\n',\n",
              " 'write a python function to remove all the even numbers from a list and return the remaining list\\n\\ndef remove_even ( my_list )  : \\n\\tresult  =  list ( filter ( lambda x :   ( x % 2 ! =  0 ) , my_list )  ) \\n\\treturn result\\n',\n",
              " 'write a function that takes two lists as input and returns a zipped list of corresponding elements\\n\\ndef zip_list ( list1, list2 )  : \\n\\treturn list ( zip ( list1, list2 )  ) \\n',\n",
              " \"write a program to to print the contents of a given file\\nfile_name  =  'temp.txt'\\nwith open ( file_name, 'r' )  as f : \\n\\tprint ( f.read (  )  ) \\n\",\n",
              " 'write a functin that returns the lcm of two input numbers\\n\\ndef lcm ( a, b )  : \\n\\tif a>b : \\n\\t\\tmin_  =  a\\n\\telse : \\n\\t\\tmin_  =  b\\n\\twhile true : \\n\\t\\tif min_%a =  = 0 and min_%b =  = 0 : \\n\\t\\t\\tbreak\\n\\t\\tmin_+ = 1\\n\\treturn min_\\n',\n",
              " 'write a program to print the unique elements in a list\\nmy_list  =  [1, 2, 4, 5, 2, 3, 1, 5, 4, 7, 8, 2, 4, 5, 2, 7, 3]\\n\\nprint ( set ( my_list )  ) \\n',\n",
              " 'write a function that returns the sum of digits of a given number\\ndef digisum ( num )  : \\n\\tsum_ = 0\\n\\twhile num > 0 : \\n\\t\\tdig  =  num % 10\\n\\t\\tsum_+ = dig\\n\\t\\tnum// = 10\\n\\treturn sum_\\n',\n",
              " 'write a program to check and print whether a number is palindrome or not\\n\\nnum  =  12321\\ntemp  =  num\\nrev  =  0\\nwhile num > 0 : \\n\\tdig  =  num % 10\\n\\trev  =  rev*10 + dig\\n\\tnum// = 10\\nif temp =  = rev  : \\n\\tprint ( \"the number is a palindrome!\" ) \\nelse : \\n\\tprint ( \"the number isn\\'t a palindrome!\" ) \\n',\n",
              " 'write a function that prints a given value, n number of times\\ndef print_n ( val, n )  : \\n\\tfor _ in range ( n )  : \\n\\t\\tprint ( val ) \\n',\n",
              " 'write a function to find the area of sqaure\\ndef square_area ( a )  : \\n\\treturn a*a\\n',\n",
              " 'write a function to find the perimeter of a square\\ndef square_perimeter ( a )  : \\n\\treturn 4*a\\n\\n',\n",
              " 'write a function to find the area of rectangle\\ndef rectangle_area ( l, b )  : \\n\\treturn l*b\\n\\n',\n",
              " 'write a function to find the permieter of a rectangle\\ndef rectangle_perimeter ( l, b )  : \\n\\treturn 2* ( l+b ) \\n\\n',\n",
              " 'write a python function to find the area of a circle, whose radius is given\\ndef findarea ( r )  :  \\n\\tpi  =  3.142\\n\\treturn pi *  ( r*r ) \\n\\n',\n",
              " 'write a function to calculate and return electricity bill. units used are given. price per unit is fixed and is increased after 750 units.\\n\\ndef calc_elect_bill ( units )  : \\n\\tif units > 0 : \\n\\t\\tif units < =  750 : \\n\\t\\t\\treturn 5*units\\n\\t\\telse : \\n\\t\\t\\treturn 5* ( 750 )  + 7* ( units-750 ) \\n\\n\\telse : \\n\\t\\treturn -1\\n',\n",
              " \"write a function to return day of a week, given the number\\ndef give_day ( n )  : \\n\\tday_dict  =  {1 :  'sunday', 2 :  'monday', 3 :  'tuesday', 4 :  'wednesday', 5 :  'thursday', 6 :  'friday', 7 :  'saturday'}\\n\\treturn day_dict[n]\\n\",\n",
              " 'write a program to calculate and print the volume of a cylender\\nr  =  3\\nh  =  5\\npi  =  3.14\\nvolume  =  pi* ( r**2 ) *h\\nprint ( volume ) \\n',\n",
              " 'write a function to calculate and return the average of input numbers\\n\\ndef calc_avg ( *args )  : \\n\\tif len ( args )  > 0 : \\n\\t\\treturn sum ( args ) /len ( args ) \\n\\treturn none\\n',\n",
              " 'write a function to calculate compound interest, given p, r, t\\ndef comp_int ( p, r, t )  : \\n\\tamount  =  p *  ( 1 +  ( r/100 )  ) **t\\n\\tinterest  =  amount - p\\n\\treturn interest\\n',\n",
              " 'write a function to calculate simple interest, given p, r, t\\ndef simp_int ( p, r, t )  : \\n\\tinterest  =   ( p*r*t ) /100\\n\\treturn interest\\n',\n",
              " 'write a program to print a given string, replacing all the vowels with \\'_\\'\\n\\nst  =  \"where is this going? could you please help me understand!\"\\nvowels  =  \"aeiouaeiou\"\\n\\nfor v in vowels : \\n\\tst  =  st.replace ( v, \\'_\\' ) \\n\\nprint ( st ) \\n',\n",
              " 'write a functio to check whether a number if perfect or not\\ndef is_perfect ( n )  : \\n\\tsum_  =  0\\n\\tfor i in range ( 1, n//2 + 1 )  : \\n\\t\\tif n%i  =  =  0 : \\n\\t\\t\\tsum_+ = i\\n\\tif sum_  =  =  n : \\n\\t\\treturn true\\n\\treturn false\\n\\n',\n",
              " 'write a function that returns seperate lists of positive and negative numbers from an input list\\ndef seperate_pn ( l )  : \\n\\tpos_list  =  []\\n\\tneg_list  =  []\\n\\tfor _ in l : \\n\\t\\tif _<0 : \\n\\t\\t\\tneg_list.append ( _ ) \\n\\t\\telse : \\n\\t\\t\\tpos_list.append ( _ ) \\n\\treturn pos_list, neg_list\\n',\n",
              " 'write a program to find and print the area of a triangle, whose hight and width are given.\\n\\nh  =  12\\nw  =  11\\narea  =  0.5*h*w\\nprint ( area ) \\n',\n",
              " 'write a function to find acceleration, given u, v and t\\n\\ndef acc ( u, v, t )  : \\n\\treturn  ( v-u ) /t\\n\\n',\n",
              " 'write a lambda function to multiply two numbers\\n\\nmultiply  =  lambda a, b :  a*b\\n\\n',\n",
              " 'write a lambda function to add two numbers\\n\\nadd  =  lambda a, b :  a+b\\n\\n',\n",
              " 'write a lambda function that gives true if the input number is even otherwise false\\n\\neven  =  lambda a :  true if a%2  =  =  0 else false\\n\\n',\n",
              " \"write a lambda function to to give character grom it's ascii value\\n\\nascii  =  lambda a :  chr ( a ) \\n\\n\",\n",
              " 'write a lambda function to that gives the number of digits in a number\\n\\ndig_cnt  =  lambda a :  len ( str ( a )  ) \\n\\n',\n",
              " \"write a program to to check if a triangle is valid or not, given it's all three angles\\n\\ndef is_valid_triangle_angle ( a, b c )  : \\n\\tif a+b+c  =  =  180 : \\n\\t\\treturn true\\n\\treturn false\\n\\n\",\n",
              " \"write a program to to check if a triangle is valid or not, given it's all three sides' length\\n\\ndef is_valid_triangle_length ( a, b c )  : \\n\\tif a>0 and b>0 and c>0 : \\n\\t\\tif a+b > c and a+c > b and b+c > a : \\n\\t\\t\\treturn true\\n\\treturn false\\n\\n\",\n",
              " \"write a lambda functio that gives the word count in a statement.\\n\\ncount_word  =  lambda s :  len ( s.split ( ' ' )  ) \\n\",\n",
              " 'write a program to extract and print digits of a number in reverse order. the number is input from user.\\n\\nnum  =  int ( input ( \"enter a number with multiple digit :  \" )  ) \\nn = 0\\nwhile num>0 : \\n\\ta  =  num%10\\n\\tnum  =  num - a\\n\\tnum  =  num/10\\n\\tprint ( int ( a ) ,end = \"\" ) \\n\\tn  =  n + 1\\n\\n',\n",
              " 'write a function that takes in height ( m )  and weight ( kg ) , calculates bmi and prints the comments\\n\\ndef bmi ( height :  \"meters\", weight :  \"kgs\" )  : \\n\\tbmi  =  weight/ ( height**2 )  \\n\\tprint ( \"your bmi is :  {0} and you are \".format ( bmi ) , end = \\'\\' ) \\n\\tif  (  bmi < 16 )  : \\n\\t   print ( \"severely underweight.\" ) \\n\\telif  (  bmi > =  16 and bmi < 18.5 )  : \\n\\t   print ( \"underweight.\" ) \\n\\telif  (  bmi > =  18.5 and bmi < 25 )  : \\n\\t   print ( \"healthy.\" ) \\n\\telif  (  bmi > =  25 and bmi < 30 )  : \\n\\t   print ( \"overweight.\" ) \\n\\telif  (  bmi > = 30 )  : \\n\\t   print ( \"severely overweight.\" )  \\n\\n',\n",
              " 'write a program that prints all the alphabets in a string and skips all other characters\\n\\nstring  =  \"$john.snow',\n",
              " '@got.bad_ending/com\"\\nfor ch in string : \\n\\tif  ( ch> = \\'a\\' and ch< = \\'z\\' )  or  ( ch> = \\'a\\' and ch< = \\'z\\' )  : \\n\\t\\tprint ( ch, end = \\'\\' ) \\n\\telse : \\n\\t\\tpass\\n\\n',\n",
              " 'write a function that takes number of disks in tower of hanaoi problem and returns the minimum number of steps required\\n\\ndef hanoi ( x )  : \\n\\tif x  =  =  1 : \\n\\t\\treturn 1\\n\\telse : \\n\\t\\treturn 2*hanoi ( x-1 )  + 1\\n\\n',\n",
              " 'write a lambda function to convert centimeters to inches\\n\\ncm_to_inch  =  lambda x :  x/2.54\\n\\n',\n",
              " 'write a lambda function to find the union of two lists\\n\\nunion  =  lambda a, b :  list ( set ( a ) |set ( b )  ) \\n\\n',\n",
              " 'write a lambda function to find the intersection of two lists\\n\\nintersection  =  lambda a, b :  list ( set ( a ) &set ( b )  ) \\n\\n',\n",
              " 'write a program that adds the square of two numbers and prints it\\n\\na  =  32\\nb  =  21\\n\\nresult  =  a**2 + b**2\\nprint ( result ) \\n\\n',\n",
              " \"write a python function to concat the input strings and there's also a choice for seperator\\n\\ndef con_str ( *args, sep  =  ' ' )  : \\n  return sep.join ( args ) \\n\\n\",\n",
              " 'write a program to print all the even numbers in a range\\n\\nr1, r2  =  1, 28\\n\\nfor _ in range ( r1, r2+1 )  : \\n  if _%2  =  =  0 : \\n\\tprint ( _ ) \\n\\n',\n",
              " 'write a python program to sort dictionary items\\ndict1  =  {\\'car\\' :  [7, 6, 3],  \\n\\t\\t\\t \\'bike\\' :  [2, 10, 3],  \\n\\t\\t\\t \\'truck\\' :  [19, 4]}\\n\\nprint ( f\"the original dictionary is  :  {str ( dict1 ) }\" )  \\n\\nres  =  dict (  )  \\nfor key in sorted ( dict1 )  :  \\n\\tres[key]  =  sorted ( dict1[key] ) \\n\\nprint ( f\"the sorted dictionary  :  {str ( res ) }\" ) \\n\\n',\n",
              " 'write a program to display date and time\\nimport datetime\\nnow  =  datetime.datetime.now (  ) \\ntime =  now.strftime ( \"%y-%m-%d %h : %m : %s\" ) \\nprint ( f\"current date and time  :  {time}\" ) \\n\\n',\n",
              " \"write a program to return the absolute value\\nnum  =  -10\\nprint ( f'absolute of {num} is {abs ( num ) }' ) \\n\\n\",\n",
              " \"write a python program to check the length of list\\nsample_list  =  ['a','b','c']\\nprint ( f'length of sample_list is {len ( sample_list ) }' ) \\n\\n\",\n",
              " \"write a python program to calculate number of days between two dates.\\nfrom datetime import date\\nf_date  =  date ( 2019, 4, 15 )  \\nl_date  =  date ( 2020, 4, 15 )  \\ndelta  =  l_date - f_date\\nprint ( f'no of days between {f_date} and {l_date} is : {delta.days}' ) \\n\\n\",\n",
              " 'write a python program to convert python objects into json strings.\\nimport json\\npython_dict  =   {\"name\" :  \"david\", \"age\" :  6, \"class\" : \"i\"}\\njson_dict  =  json.dumps ( python_dict, sort_keys = true, indent = 4 ) \\nprint ( f\"json dict  :  {json_dict}\" ) \\n\\n',\n",
              " \"write a python program to get the largest number from a list\\ndef max_num_in_list ( list )  : \\n\\tmax  =  list[0]\\n\\tfor a in list : \\n\\t\\tmax  =  a if a > max else max\\n\\treturn max\\nprint ( f'max_num_in_list [1, 10, -8, 0], ans : {max_num_in_list ( [1, 10, -8, 0] ) }' ) \\n\\n\",\n",
              " \"write a python program to remove duplicates from a list\\na  =  [10,20,30,20,10,50,60,40,80,50,40]\\n\\ndup_items  =  set (  ) \\nuniq_items  =  []\\nfor x in a : \\n\\tif x not in dup_items : \\n\\t\\tuniq_items.append ( x ) \\n\\t\\tdup_items.add ( x ) \\n\\nprint ( f'dup_items : {dup_items}' ) \\n\\n\",\n",
              " \"write a python program to flatten a shallow list\\nimport itertools\\noriginal_list  =  [[2,4,3],[1,5,6], [9], [7,9,0], [1,2,3,4]]\\nnew_merged_list  =  list ( itertools.chain ( *original_list )  ) \\nprint ( f'merged list/flatten : {new_merged_list}' ) \\n\\n\",\n",
              " \"write a python program to create multiple list\\n\\nobj  =  {}\\nfor i in range ( 1, 11 )  : \\n\\tobj[str ( i ) ]  =  []\\nprint ( f'create multiple list : {obj}' ) \\n\\n\",\n",
              " \"write a python program to merge two dictionaries\\n\\nd1  =  {'a' :  100, 'b' :  200}\\nd2  =  {'x' :  300, 'y' :  200}\\nd  =  d1.copy (  ) \\nd.update ( d2 ) \\nprint ( f'merge two dictionaries : {d}' ) \\n\\n\",\n",
              " \"write a python program to sum all the items in a dictionary\\n\\nmy_dict  =  {'data1' : 100,'data2' : -54,'data3' : 247}\\nprint ( f'sum all the items in a dictionary : {sum ( my_dict.values (  )  ) }' ) \\n\\n\",\n",
              " \"write a python program to get the maximum and minimum value in a dictionary\\n\\nmy_dict  =  {'x' : 500, 'y' : 5874, 'z' :  560}\\n\\nkey_max  =  max ( my_dict.keys (  ) , key =  ( lambda k :  my_dict[k] )  ) \\nkey_min  =  min ( my_dict.keys (  ) , key =  ( lambda k :  my_dict[k] )  ) \\n\\nprint ( 'maximum value in a dictionary :  ',my_dict[key_max] ) \\nprint ( 'minimum value in a dictionary :  ',my_dict[key_min] ) \\n\\n\",\n",
              " 'write a python program to do nothing for a condition\\n\\nif 1 + 1  =  =  2 : \\n\\tpass\\n\\n',\n",
              " 'write a python program to make use of enumerate method\\n\\nfor count, value in enumerate ( obj )  : \\n\\tprint ( count, value ) \\n\\n',\n",
              " \"write a python program to make use of setdefault for missing dictionary keys\\na_dict  =  {'a' : 1}\\na_dict.setdefault ( 'b',2 ) \\nprint ( f'after appending with new value : {a_dict}' ) \\n\\n\",\n",
              " \"write a python program to make use of maps\\n\\ndef square ( number )  : \\n\\treturn number ** 2\\n\\nnumbers  =  [1, 2, 3, 4, 5]\\n\\nsquared  =  map ( square, numbers ) \\n\\nprint ( f'mapped numbers : {list ( squared ) }' ) \\n\\n\",\n",
              " \"write a python program to make use of modulo operator\\n\\nprint ( f'modulo 15 % 4 :  sol->{15 % 4}' ) \\n\\n\",\n",
              " \"write a python program to explain enclosing and global scope\\n\\nx  =  'global'\\n\\ndef f (  )  : \\n\\tx  =  'enclosing'\\n\\tdef g (  )  : \\n\\t\\tprint ( x ) \\n\\tg (  ) \\n\\treturn x\\nobj1  =  f (  ) \\nprint ( 'explain global scope : ',obj1 ) \\n\\n\",\n",
              " \"write a python program to expain local and global scope\\n\\ndef f1 (  )  : \\n\\tx  =  'enclosing'\\n\\tdef g (  )  : \\n\\t\\tx  =  'local'\\n\\t\\treturn x\\n\\tx = g (  ) \\n\\treturn x\\nobj2  =  f1 (  ) \\nprint ( 'explain local scope : ',obj2 ) \\n\\n\",\n",
              " \"write a python program to make use of regular expression for matching\\nimport re\\nprint ( 'find the characters in the given string : ',re.findall ( r'[a-z]+', '123foo456', flags = re.ignorecase )  ) \\n\\n\",\n",
              " \"write a python program to make use of regular expression for matching\\ns  =  'foo123bar'\\nm  =  re.findall ( '123', s ) \\nprint ( 'find the number position : ',m ) \\n\\n\",\n",
              " \"write a python program to convert lower string to uppercase\\na  =  'string'\\nprint ( f'convert lowercase to uppercase : {a.upper (  ) }' ) \\n\\n\",\n",
              " \"write a python program to convert uppercase string to lower\\na  =  'string'\\nprint ( f'convert lowercase to uppercase : {a.lower (  ) }' ) \\n\\n\",\n",
              " \"write a python program to find the square root\\nnum  =  8 \\n\\nnum_sqrt  =  num ** 0.5\\nprint ( 'the square root of %0.3f is %0.3f'% ( num ,num_sqrt )  ) \\n\\n\",\n",
              " \"write a python program to convert kilometers to miles\\nkilometers  =  10.0\\n\\nconv_fac  =  0.621371\\n\\nmiles  =  kilometers * conv_fac\\nprint ( '%0.2f kilometers is equal to %0.2f miles' % ( kilometers,miles )  ) \\n\\n\",\n",
              " \"write a python program to convert celsius to fahrenheit\\ncelsius  =  37.5\\nfahrenheit  =   ( celsius * 1.8 )  + 32\\nprint ( '%0.1f degree celsius is equal to %0.1f degree fahrenheit' % ( celsius,fahrenheit )  ) \\n\\n\",\n",
              " 'write a python program to check if a number is positive, negative or 0\\nnum  =  10\\nif num > 0 : \\n   print ( \"positive number\" ) \\nelif num  =  =  0 : \\n   print ( \"zero\" ) \\nelse : \\n   print ( \"negative number\" ) \\n\\n',\n",
              " 'python program to check if a number is odd or even\\nnum  =  100\\nif  ( num % 2 )   =  =  0 : \\n   print ( \"{0} is even\".format ( num )  ) \\nelse : \\n   print ( \"{0} is odd\".format ( num )  ) \\n\\n',\n",
              " \"python program to display the multiplication table\\nnum  =  12\\nfor i in range ( 1, 11 )  : \\n   print ( num, 'x', i, ' = ', num*i ) \\n\\n\",\n",
              " 'write a program for rolling the dices\\nimport random\\nmin  =  1\\nmax  =  6\\n\\nprint ( \"rolling the dices...and the values are\",random.randint ( min, max )  ) \\nprint ( \"rolling the dices...and the values are\",random.randint ( min, max )  ) \\n\\n',\n",
              " 'write a python program to calculate the average\\nlist1  =  [1,3,4,5]\\naverage  =   ( sum ( list1 )  )  / len ( list1 ) \\nprint ( f\"the average score is :   {average} \" ) \\n\\n',\n",
              " \"write a python program to print reverse list\\nprint ( f'reverese the given list elements : {list1[ :  : -1]}' ) \\n\\n\",\n",
              " 'write a python program for creating the thread\\nimport threading\\nfrom threading import thread\\nimport time\\n\\ndef print_time (  threadname, delay )  : \\n\\tcount  =  0\\n\\twhile count < 5 : \\n\\t\\ttime.sleep ( delay ) \\n\\t\\tcount + =  1\\n\\t\\tprint ( \"%s :  %s\" %  (  threadname, time.ctime ( time.time (  )  )   )  ) \\n\\n  try : \\n\\t  thread ( target = print_time, args =  ( \"thread-1\", 2,  )  ) .start (  )  \\n\\t  thread ( target = print_time, args =  ( \"thread-1\", 4,  )  ) .start (  )  \\n  except : \\n\\t  print ( \"error :  unable to start thread\" ) \\n\\n',\n",
              " \"write a python program to check a num is less than 1000\\ndef near_thousand ( n )  : \\n\\t  return  (  ( abs ( 1000 - n )  < =  100 )  or  ( abs ( 2000 - n )  < =  100 )  ) \\nprint ( 'near to 1000',near_thousand ( 1000 )  ) \\nprint ( 'near to 1300',near_thousand ( 1300 )  ) \\n\\n\",\n",
              " \"write a python program to convert lower case to upper for list of elements\\n\\nx  =  ['ab', 'cd']\\nfor i in x : \\n\\tprint ( i.upper (  )  ) \\n\\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "To4h9s6nFtYm",
        "outputId": "ec8cdbaf-0ff4-426f-a1aa-d1255067d5f4"
      },
      "source": [
        "sent[0] = sent[0].replace('#', '')\r\n",
        "sent[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UB1HBi6G6y5",
        "outputId": "d95be580-a6da-401d-db6c-7ee54f631af2"
      },
      "source": [
        "Title = []\r\n",
        "py_code = []\r\n",
        "for s in sent:\r\n",
        "  words = s.split('\\n')\r\n",
        "  Title.append(words[0])\r\n",
        "  py_code.append(words[1:])\r\n",
        "\r\n",
        "print(len(Title), len(py_code))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4650 4650\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSYxJQ5UIKOO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5d7943e8-bfa7-4fbe-84ee-041fe88c6ffb"
      },
      "source": [
        "'''\r\n",
        "for i in range(len(py_code)):\r\n",
        "  py_code[i] = ' \\n '.join(py_code[i])\r\n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor i in range(len(py_code)):\\n  py_code[i] = ' \\n '.join(py_code[i])\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0zxb8-QwwcA",
        "outputId": "c2b8cd5c-c0b6-42c7-c901-771974708f35"
      },
      "source": [
        "py_code[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " ['num1  =  1.5',\n",
              "  'num2  =  6.3',\n",
              "  'sum  =  num1 + num2',\n",
              "  \"print ( f'sum :  {sum}' ) \",\n",
              "  ''],\n",
              " ['def add_two_numbers ( num1, num2 )  : ',\n",
              "  '\\tsum  =  num1 + num2',\n",
              "  '\\treturn sum',\n",
              "  ''],\n",
              " ['',\n",
              "  'num1  =  10',\n",
              "  'num2  =  12',\n",
              "  'num3  =  14',\n",
              "  'if  ( num1 > =  num2 )  and  ( num1 > =  num3 )  : ',\n",
              "  '   largest  =  num1',\n",
              "  'elif  ( num2 > =  num1 )  and  ( num2 > =  num3 )  : ',\n",
              "  '   largest  =  num2',\n",
              "  'else : ',\n",
              "  '   largest  =  num3',\n",
              "  \"print ( f'largest : {largest}' ) \",\n",
              "  ''],\n",
              " ['num1  =  10',\n",
              "  'num2  =  12',\n",
              "  'num3  =  14',\n",
              "  'if  ( num1 < =  num2 )  and  ( num1 < =  num3 )  : ',\n",
              "  '   smallest  =  num1',\n",
              "  'elif  ( num2 < =  num1 )  and  ( num2 < =  num3 )  : ',\n",
              "  '   smallest  =  num2',\n",
              "  'else : ',\n",
              "  '   smallest  =  num3',\n",
              "  \"print ( f'smallest : {smallest}' ) \",\n",
              "  '']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7OHRdD_JJh9",
        "outputId": "f4c6bbeb-6c75-4a22-d273-654273cff1db"
      },
      "source": [
        "print(py_code[2])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['def add_two_numbers ( num1, num2 )  : ', '\\tsum  =  num1 + num2', '\\treturn sum', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJQiU0kZJ9ac",
        "outputId": "022d1b3b-eb7c-45b9-877c-8357d27a55d0"
      },
      "source": [
        "df = pd.DataFrame({'Title': Title, 'Target_code': py_code})\r\n",
        "df.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4650, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "XvJ7BaPwKY5i",
        "outputId": "38b3ee68-ed2c-4db2-9174-fb353a78ae3a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Target_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python program to add two numbers</td>\n",
              "      <td>[num1  =  1.5, num2  =  6.3, sum  =  num1 + nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>[def add_two_numbers ( num1, num2 )  : , \\tsum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>[, num1  =  10, num2  =  12, num3  =  14, if  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>[num1  =  10, num2  =  12, num3  =  14, if  ( ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title                                        Target_code\n",
              "0                                                                                                    []\n",
              "1         write a python program to add two numbers   [num1  =  1.5, num2  =  6.3, sum  =  num1 + nu...\n",
              "2  write a python function to add two user provid...  [def add_two_numbers ( num1, num2 )  : , \\tsum...\n",
              "3  write a program to find and print the largest ...  [, num1  =  10, num2  =  12, num3  =  14, if  ...\n",
              "4  write a program to find and print the smallest...  [num1  =  10, num2  =  12, num3  =  14, if  ( ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCk4OxcFmSvn"
      },
      "source": [
        "# Embedding vector creation using word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EYtyzTfPMRM"
      },
      "source": [
        "en = en = spacy.load('en_core_web_sm')\r\n",
        "def Tokenize(sentence):\r\n",
        "  sentence = str(sentence).replace('\\n', '')\r\n",
        "  return [tok.text for tok in en.tokenizer(sentence)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-zDfoEFQHHG"
      },
      "source": [
        "import gensim\r\n",
        "w2v_dim = 256\r\n",
        "w2v_min_count = 2\r\n",
        "w2v_window = 3\r\n",
        "target = []\r\n",
        "for sent in df['Target_code'].values:\r\n",
        "  sent_token = Tokenize(sent)\r\n",
        "  target.append(sent_token)\r\n",
        "w2v_model = gensim.models.Word2Vec(target, size = w2v_dim, window = w2v_window, min_count = w2v_min_count)\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRBNGoS9UAtV"
      },
      "source": [
        "w2v_model.save('embeddings.txt')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf-csKV0mdR4"
      },
      "source": [
        "# Preparation of Source and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCbkU2QO5WuH"
      },
      "source": [
        "SRC = Field(tokenize = 'spacy', \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)\r\n",
        "\r\n",
        "TRG = Field(tokenize = 'spacy', \r\n",
        "            init_token = '<sos>', \r\n",
        "            eos_token = '<eos>', \r\n",
        "            lower = True, \r\n",
        "            batch_first = True)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gGqE7-o8YIM"
      },
      "source": [
        "fields = [('Title', SRC),('Target_code',TRG)]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gXgIdhRLPLV"
      },
      "source": [
        "example = [legacy.data.Example.fromlist([df.Title[i],df.Target_code[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHBTVhZT82Hq"
      },
      "source": [
        "CodeDataset = legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnDxnwmBNE0c",
        "outputId": "078fdff4-e039-4881-fd1a-b9e417a32152"
      },
      "source": [
        "vars(CodeDataset.examples[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Target_code': [], 'Title': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1aMifXQNo5u"
      },
      "source": [
        "(train, test, val) = CodeDataset.split(split_ratio=[0.80, 0.10, 0.10], random_state=random.seed(SEED))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXYKdSOjOA8Z"
      },
      "source": [
        "SRC.build_vocab(train, min_freq = 2)\r\n",
        "TRG.build_vocab(train, min_freq = 2)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TeTYDAFOL4E",
        "outputId": "5e7955c5-7110-444b-9c14-de72ca7dac17"
      },
      "source": [
        "print(\"size of SRC vocab: \", len(SRC.vocab))\r\n",
        "print('size of TRG vocab: ', len(TRG.vocab))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of SRC vocab:  1419\n",
            "size of TRG vocab:  4505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "eb53921547c3412281a8e3e2b22adfe0",
            "7d149138aff6460e8be2f151efe60ba1",
            "98a9bf85310a4648a03ed01bf0d640e3",
            "dfa6526c89f0459cb36e1abb1b128b74",
            "61a79a10db8b4e109c3b0da5d652432e",
            "0ed43e52fcd44adaadb3dd7b0c1befdb",
            "1edbc118d80b4f2d81b3895f0762b481",
            "03be22ac73b64fdfa2f528f5c033c732"
          ]
        },
        "id": "OG15qFTAWV1j",
        "outputId": "4f4367aa-c91d-4e53-e5fb-3e59dac8e230"
      },
      "source": [
        "from tqdm import tqdm_notebook\r\n",
        "word2vec_vectors = []\r\n",
        "for token, idx in tqdm_notebook(TRG.vocab.stoi.items()):\r\n",
        "  if token in w2v_model.wv.vocab.keys():\r\n",
        "    word2vec_vectors.append(torch.FloatTensor(w2v_model[token]))\r\n",
        "  else:\r\n",
        "    word2vec_vectors.append(torch.zeros(w2v_dim))\r\n",
        "TRG.vocab.set_vectors(TRG.vocab.stoi, word2vec_vectors, w2v_dim)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb53921547c3412281a8e3e2b22adfe0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4505.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb8ethvxOQVk"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxWc9sPCOSAd"
      },
      "source": [
        "BATCH_SIZE = 64\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train, val, test),\r\n",
        "    sort = False, \r\n",
        "     batch_size = BATCH_SIZE,\r\n",
        "     device = device)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJIUV30mqDV"
      },
      "source": [
        "# Encoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ImLedZ8Ol1V"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 input_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,\r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 max_length = 100):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim,\r\n",
        "                                                  dropout, \r\n",
        "                                                  device) \r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        batch_size = src.shape[0]\r\n",
        "        src_len = src.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "        \r\n",
        "        #pos = [batch size, src len]\r\n",
        "        \r\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            src = layer(src, src_mask)\r\n",
        "            \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "            \r\n",
        "        return src"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJSpOIruOrT-"
      },
      "source": [
        "class EncoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim,  \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, src, src_mask):\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        #src_mask = [batch size, 1, 1, src len] \r\n",
        "                \r\n",
        "        #self attention\r\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _src = self.positionwise_feedforward(src)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\r\n",
        "        \r\n",
        "        #src = [batch size, src len, hid dim]\r\n",
        "        \r\n",
        "        return src"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVj2cG-bO4cx"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        assert hid_dim % n_heads == 0\r\n",
        "        \r\n",
        "        self.hid_dim = hid_dim\r\n",
        "        self.n_heads = n_heads\r\n",
        "        self.head_dim = hid_dim // n_heads\r\n",
        "        \r\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\r\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, query, key, value, mask = None):\r\n",
        "        \r\n",
        "        batch_size = query.shape[0]\r\n",
        "        \r\n",
        "        #query = [batch size, query len, hid dim]\r\n",
        "        #key = [batch size, key len, hid dim]\r\n",
        "        #value = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = self.fc_q(query)\r\n",
        "        K = self.fc_k(key)\r\n",
        "        V = self.fc_v(value)\r\n",
        "        \r\n",
        "        #Q = [batch size, query len, hid dim]\r\n",
        "        #K = [batch size, key len, hid dim]\r\n",
        "        #V = [batch size, value len, hid dim]\r\n",
        "                \r\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\r\n",
        "        \r\n",
        "        #Q = [batch size, n heads, query len, head dim]\r\n",
        "        #K = [batch size, n heads, key len, head dim]\r\n",
        "        #V = [batch size, n heads, value len, head dim]\r\n",
        "                \r\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\r\n",
        "        \r\n",
        "        #energy = [batch size, n heads, query len, key len]\r\n",
        "        \r\n",
        "        if mask is not None:\r\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\r\n",
        "        \r\n",
        "        attention = torch.softmax(energy, dim = -1)\r\n",
        "                \r\n",
        "        #attention = [batch size, n heads, query len, key len]\r\n",
        "                \r\n",
        "        x = torch.matmul(self.dropout(attention), V)\r\n",
        "        \r\n",
        "        #x = [batch size, n heads, query len, head dim]\r\n",
        "        \r\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\r\n",
        "        \r\n",
        "        #x = [batch size, query len, n heads, head dim]\r\n",
        "        \r\n",
        "        x = x.view(batch_size, -1, self.hid_dim)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        x = self.fc_o(x)\r\n",
        "        \r\n",
        "        #x = [batch size, query len, hid dim]\r\n",
        "        \r\n",
        "        return x, attention"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA3PdqZwO6qo"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\r\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\r\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, pf dim]\r\n",
        "        \r\n",
        "        x = self.fc_2(x)\r\n",
        "        \r\n",
        "        #x = [batch size, seq len, hid dim]\r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt4TC5yTmxLC"
      },
      "source": [
        "#Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9q5ukPYO-Xw"
      },
      "source": [
        "class Decoder(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 output_dim, \r\n",
        "                 hid_dim, \r\n",
        "                 n_layers, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device,\r\n",
        "                 pre_trained_emb,\r\n",
        "                 max_length = 500):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.device = device\r\n",
        "        self.pre_trained_emb = pre_trained_emb\r\n",
        "        self.tok_embedding = nn.Embedding.from_pretrained(self.pre_trained_emb)\r\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\r\n",
        "        \r\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \r\n",
        "                                                  n_heads, \r\n",
        "                                                  pf_dim, \r\n",
        "                                                  dropout, \r\n",
        "                                                  device)\r\n",
        "                                     for _ in range(n_layers)])\r\n",
        "        \r\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "                \r\n",
        "        batch_size = trg.shape[0]\r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\r\n",
        "                            \r\n",
        "        #pos = [batch size, trg len]\r\n",
        "            \r\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\r\n",
        "                \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        for layer in self.layers:\r\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        output = self.fc_out(trg)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "            \r\n",
        "        return output, attention"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXTXfD7aPItR"
      },
      "source": [
        "class DecoderLayer(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 hid_dim, \r\n",
        "                 n_heads, \r\n",
        "                 pf_dim, \r\n",
        "                 dropout, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\r\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\r\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \r\n",
        "                                                                     pf_dim, \r\n",
        "                                                                     dropout)\r\n",
        "        self.dropout = nn.Dropout(dropout)\r\n",
        "        \r\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        \r\n",
        "        #self attention\r\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "            \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "            \r\n",
        "        #encoder attention\r\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\r\n",
        "        # query, key, value\r\n",
        "        \r\n",
        "        #dropout, residual connection and layer norm\r\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\r\n",
        "                    \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        \r\n",
        "        #positionwise feedforward\r\n",
        "        _trg = self.positionwise_feedforward(trg)\r\n",
        "        \r\n",
        "        #dropout, residual and layer norm\r\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len, hid dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return trg, attention"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjx8CoTaPOyu"
      },
      "source": [
        "class Seq2Seq(nn.Module):\r\n",
        "    def __init__(self, \r\n",
        "                 encoder, \r\n",
        "                 decoder, \r\n",
        "                 src_pad_idx, \r\n",
        "                 trg_pad_idx, \r\n",
        "                 device):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.encoder = encoder\r\n",
        "        self.decoder = decoder\r\n",
        "        self.src_pad_idx = src_pad_idx\r\n",
        "        self.trg_pad_idx = trg_pad_idx\r\n",
        "        self.device = device\r\n",
        "        \r\n",
        "    def make_src_mask(self, src):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        \r\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "\r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "\r\n",
        "        return src_mask\r\n",
        "    \r\n",
        "    def make_trg_mask(self, trg):\r\n",
        "        \r\n",
        "        #trg = [batch size, trg len]\r\n",
        "        \r\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\r\n",
        "        \r\n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\r\n",
        "        \r\n",
        "        trg_len = trg.shape[1]\r\n",
        "        \r\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\r\n",
        "        \r\n",
        "        #trg_sub_mask = [trg len, trg len]\r\n",
        "            \r\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\r\n",
        "        \r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        return trg_mask\r\n",
        "\r\n",
        "    def forward(self, src, trg):\r\n",
        "        \r\n",
        "        #src = [batch size, src len]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "                \r\n",
        "        src_mask = self.make_src_mask(src)\r\n",
        "        trg_mask = self.make_trg_mask(trg)\r\n",
        "        \r\n",
        "        #src_mask = [batch size, 1, 1, src len]\r\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\r\n",
        "        \r\n",
        "        enc_src = self.encoder(src, src_mask)\r\n",
        "        \r\n",
        "        #enc_src = [batch size, src len, hid dim]\r\n",
        "                \r\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        #output = [batch size, trg len, output dim]\r\n",
        "        #attention = [batch size, n heads, trg len, src len]\r\n",
        "        \r\n",
        "        return output, attention"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhWg4vahPUHD"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "HID_DIM = 256\r\n",
        "ENC_LAYERS = 3\r\n",
        "DEC_LAYERS = 3\r\n",
        "ENC_HEADS = 8\r\n",
        "DEC_HEADS = 8\r\n",
        "ENC_PF_DIM = 512\r\n",
        "DEC_PF_DIM = 512\r\n",
        "ENC_DROPOUT = 0.1\r\n",
        "DEC_DROPOUT = 0.1\r\n",
        "pre_trained_emb = torch.FloatTensor(TRG.vocab.vectors)\r\n",
        "enc = Encoder(INPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              ENC_LAYERS, \r\n",
        "              ENC_HEADS, \r\n",
        "              ENC_PF_DIM, \r\n",
        "              ENC_DROPOUT, \r\n",
        "              device)\r\n",
        "\r\n",
        "dec = Decoder(OUTPUT_DIM, \r\n",
        "              HID_DIM, \r\n",
        "              DEC_LAYERS, \r\n",
        "              DEC_HEADS, \r\n",
        "              DEC_PF_DIM, \r\n",
        "              DEC_DROPOUT,\r\n",
        "              device,\r\n",
        "              pre_trained_emb) \r\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggFdUthRPs9a"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\r\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM16bNPrPyYA",
        "outputId": "3c866de4-b2fe-4428-8fed-5bb10e0e1906"
      },
      "source": [
        "def count_parameters(model):\r\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,628,313 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7yLzZ0LP4jd"
      },
      "source": [
        "def initialize_weights(m):\r\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\r\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaq4MEvCP8C1"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXe-C5NoQBBT"
      },
      "source": [
        "LEARNING_RATE = 0.0005\r\n",
        "\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQRu87VlQEyb"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZoLagKQQKUh"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in enumerate(iterator):\r\n",
        "        \r\n",
        "        src = batch.Title\r\n",
        "        trg = batch.Target_code\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output, _ = model(src, trg[:,:-1])\r\n",
        "                \r\n",
        "        #output = [batch size, trg len - 1, output dim]\r\n",
        "        #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "        output = output.contiguous().view(-1, output_dim)\r\n",
        "        trg = trg[:,1:].contiguous().view(-1)\r\n",
        "                \r\n",
        "        #output = [batch size * trg len - 1, output dim]\r\n",
        "        #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwiD11IQQSks"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in enumerate(iterator):\r\n",
        "\r\n",
        "            src = batch.Title\r\n",
        "            trg = batch.Target_code\r\n",
        "\r\n",
        "            output, _ = model(src, trg[:,:-1])\r\n",
        "            \r\n",
        "            #output = [batch size, trg len - 1, output dim]\r\n",
        "            #trg = [batch size, trg len]\r\n",
        "            \r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output.contiguous().view(-1, output_dim)\r\n",
        "            trg = trg[:,1:].contiguous().view(-1)\r\n",
        "            \r\n",
        "            #output = [batch size * trg len - 1, output dim]\r\n",
        "            #trg = [batch size * trg len - 1]\r\n",
        "            \r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBldrkgZQZaN"
      },
      "source": [
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBL0qrN0QeKm",
        "outputId": "6e9abbe8-fb54-4dad-fae4-dbd465682bc9"
      },
      "source": [
        "N_EPOCHS = 50\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 3s\n",
            "\tTrain Loss: 5.243 | Train PPL: 189.329\n",
            "\t Val. Loss: 3.074 |  Val. PPL:  21.630\n",
            "Epoch: 02 | Time: 0m 3s\n",
            "\tTrain Loss: 4.286 | Train PPL:  72.708\n",
            "\t Val. Loss: 2.927 |  Val. PPL:  18.670\n",
            "Epoch: 03 | Time: 0m 3s\n",
            "\tTrain Loss: 3.981 | Train PPL:  53.593\n",
            "\t Val. Loss: 2.724 |  Val. PPL:  15.245\n",
            "Epoch: 04 | Time: 0m 3s\n",
            "\tTrain Loss: 3.668 | Train PPL:  39.187\n",
            "\t Val. Loss: 2.512 |  Val. PPL:  12.328\n",
            "Epoch: 05 | Time: 0m 3s\n",
            "\tTrain Loss: 3.356 | Train PPL:  28.680\n",
            "\t Val. Loss: 2.350 |  Val. PPL:  10.484\n",
            "Epoch: 06 | Time: 0m 3s\n",
            "\tTrain Loss: 3.037 | Train PPL:  20.844\n",
            "\t Val. Loss: 2.144 |  Val. PPL:   8.532\n",
            "Epoch: 07 | Time: 0m 3s\n",
            "\tTrain Loss: 2.758 | Train PPL:  15.762\n",
            "\t Val. Loss: 2.002 |  Val. PPL:   7.403\n",
            "Epoch: 08 | Time: 0m 3s\n",
            "\tTrain Loss: 2.456 | Train PPL:  11.662\n",
            "\t Val. Loss: 1.866 |  Val. PPL:   6.460\n",
            "Epoch: 09 | Time: 0m 3s\n",
            "\tTrain Loss: 2.189 | Train PPL:   8.924\n",
            "\t Val. Loss: 1.734 |  Val. PPL:   5.665\n",
            "Epoch: 10 | Time: 0m 3s\n",
            "\tTrain Loss: 1.923 | Train PPL:   6.845\n",
            "\t Val. Loss: 1.599 |  Val. PPL:   4.946\n",
            "Epoch: 11 | Time: 0m 3s\n",
            "\tTrain Loss: 1.682 | Train PPL:   5.376\n",
            "\t Val. Loss: 1.518 |  Val. PPL:   4.565\n",
            "Epoch: 12 | Time: 0m 3s\n",
            "\tTrain Loss: 1.477 | Train PPL:   4.380\n",
            "\t Val. Loss: 1.405 |  Val. PPL:   4.074\n",
            "Epoch: 13 | Time: 0m 3s\n",
            "\tTrain Loss: 1.286 | Train PPL:   3.618\n",
            "\t Val. Loss: 1.339 |  Val. PPL:   3.816\n",
            "Epoch: 14 | Time: 0m 3s\n",
            "\tTrain Loss: 1.133 | Train PPL:   3.105\n",
            "\t Val. Loss: 1.277 |  Val. PPL:   3.585\n",
            "Epoch: 15 | Time: 0m 3s\n",
            "\tTrain Loss: 0.987 | Train PPL:   2.684\n",
            "\t Val. Loss: 1.237 |  Val. PPL:   3.445\n",
            "Epoch: 16 | Time: 0m 3s\n",
            "\tTrain Loss: 0.896 | Train PPL:   2.449\n",
            "\t Val. Loss: 1.237 |  Val. PPL:   3.446\n",
            "Epoch: 17 | Time: 0m 3s\n",
            "\tTrain Loss: 0.785 | Train PPL:   2.193\n",
            "\t Val. Loss: 1.225 |  Val. PPL:   3.403\n",
            "Epoch: 18 | Time: 0m 3s\n",
            "\tTrain Loss: 0.722 | Train PPL:   2.058\n",
            "\t Val. Loss: 1.201 |  Val. PPL:   3.322\n",
            "Epoch: 19 | Time: 0m 3s\n",
            "\tTrain Loss: 0.663 | Train PPL:   1.941\n",
            "\t Val. Loss: 1.178 |  Val. PPL:   3.249\n",
            "Epoch: 20 | Time: 0m 3s\n",
            "\tTrain Loss: 0.620 | Train PPL:   1.859\n",
            "\t Val. Loss: 1.234 |  Val. PPL:   3.433\n",
            "Epoch: 21 | Time: 0m 3s\n",
            "\tTrain Loss: 0.580 | Train PPL:   1.785\n",
            "\t Val. Loss: 1.173 |  Val. PPL:   3.232\n",
            "Epoch: 22 | Time: 0m 3s\n",
            "\tTrain Loss: 0.546 | Train PPL:   1.727\n",
            "\t Val. Loss: 1.215 |  Val. PPL:   3.369\n",
            "Epoch: 23 | Time: 0m 3s\n",
            "\tTrain Loss: 0.507 | Train PPL:   1.660\n",
            "\t Val. Loss: 1.156 |  Val. PPL:   3.178\n",
            "Epoch: 24 | Time: 0m 3s\n",
            "\tTrain Loss: 0.483 | Train PPL:   1.622\n",
            "\t Val. Loss: 1.156 |  Val. PPL:   3.176\n",
            "Epoch: 25 | Time: 0m 3s\n",
            "\tTrain Loss: 0.464 | Train PPL:   1.591\n",
            "\t Val. Loss: 1.200 |  Val. PPL:   3.320\n",
            "Epoch: 26 | Time: 0m 3s\n",
            "\tTrain Loss: 0.434 | Train PPL:   1.543\n",
            "\t Val. Loss: 1.155 |  Val. PPL:   3.173\n",
            "Epoch: 27 | Time: 0m 3s\n",
            "\tTrain Loss: 0.414 | Train PPL:   1.513\n",
            "\t Val. Loss: 1.176 |  Val. PPL:   3.240\n",
            "Epoch: 28 | Time: 0m 3s\n",
            "\tTrain Loss: 0.392 | Train PPL:   1.480\n",
            "\t Val. Loss: 1.199 |  Val. PPL:   3.317\n",
            "Epoch: 29 | Time: 0m 3s\n",
            "\tTrain Loss: 0.384 | Train PPL:   1.469\n",
            "\t Val. Loss: 1.177 |  Val. PPL:   3.244\n",
            "Epoch: 30 | Time: 0m 3s\n",
            "\tTrain Loss: 0.372 | Train PPL:   1.451\n",
            "\t Val. Loss: 1.205 |  Val. PPL:   3.337\n",
            "Epoch: 31 | Time: 0m 3s\n",
            "\tTrain Loss: 0.348 | Train PPL:   1.416\n",
            "\t Val. Loss: 1.195 |  Val. PPL:   3.303\n",
            "Epoch: 32 | Time: 0m 3s\n",
            "\tTrain Loss: 0.348 | Train PPL:   1.416\n",
            "\t Val. Loss: 1.219 |  Val. PPL:   3.383\n",
            "Epoch: 33 | Time: 0m 3s\n",
            "\tTrain Loss: 0.336 | Train PPL:   1.399\n",
            "\t Val. Loss: 1.252 |  Val. PPL:   3.496\n",
            "Epoch: 34 | Time: 0m 3s\n",
            "\tTrain Loss: 0.320 | Train PPL:   1.377\n",
            "\t Val. Loss: 1.248 |  Val. PPL:   3.483\n",
            "Epoch: 35 | Time: 0m 3s\n",
            "\tTrain Loss: 0.320 | Train PPL:   1.377\n",
            "\t Val. Loss: 1.211 |  Val. PPL:   3.356\n",
            "Epoch: 36 | Time: 0m 3s\n",
            "\tTrain Loss: 0.301 | Train PPL:   1.352\n",
            "\t Val. Loss: 1.310 |  Val. PPL:   3.707\n",
            "Epoch: 37 | Time: 0m 3s\n",
            "\tTrain Loss: 0.295 | Train PPL:   1.343\n",
            "\t Val. Loss: 1.299 |  Val. PPL:   3.664\n",
            "Epoch: 38 | Time: 0m 3s\n",
            "\tTrain Loss: 0.295 | Train PPL:   1.343\n",
            "\t Val. Loss: 1.285 |  Val. PPL:   3.615\n",
            "Epoch: 39 | Time: 0m 3s\n",
            "\tTrain Loss: 0.288 | Train PPL:   1.333\n",
            "\t Val. Loss: 1.294 |  Val. PPL:   3.647\n",
            "Epoch: 40 | Time: 0m 3s\n",
            "\tTrain Loss: 0.281 | Train PPL:   1.324\n",
            "\t Val. Loss: 1.303 |  Val. PPL:   3.680\n",
            "Epoch: 41 | Time: 0m 3s\n",
            "\tTrain Loss: 0.261 | Train PPL:   1.298\n",
            "\t Val. Loss: 1.319 |  Val. PPL:   3.741\n",
            "Epoch: 42 | Time: 0m 3s\n",
            "\tTrain Loss: 0.265 | Train PPL:   1.303\n",
            "\t Val. Loss: 1.346 |  Val. PPL:   3.843\n",
            "Epoch: 43 | Time: 0m 3s\n",
            "\tTrain Loss: 0.249 | Train PPL:   1.282\n",
            "\t Val. Loss: 1.339 |  Val. PPL:   3.814\n",
            "Epoch: 44 | Time: 0m 3s\n",
            "\tTrain Loss: 0.240 | Train PPL:   1.271\n",
            "\t Val. Loss: 1.376 |  Val. PPL:   3.959\n",
            "Epoch: 45 | Time: 0m 3s\n",
            "\tTrain Loss: 0.237 | Train PPL:   1.268\n",
            "\t Val. Loss: 1.337 |  Val. PPL:   3.807\n",
            "Epoch: 46 | Time: 0m 3s\n",
            "\tTrain Loss: 0.230 | Train PPL:   1.259\n",
            "\t Val. Loss: 1.346 |  Val. PPL:   3.843\n",
            "Epoch: 47 | Time: 0m 3s\n",
            "\tTrain Loss: 0.225 | Train PPL:   1.252\n",
            "\t Val. Loss: 1.422 |  Val. PPL:   4.146\n",
            "Epoch: 48 | Time: 0m 3s\n",
            "\tTrain Loss: 0.222 | Train PPL:   1.249\n",
            "\t Val. Loss: 1.399 |  Val. PPL:   4.053\n",
            "Epoch: 49 | Time: 0m 3s\n",
            "\tTrain Loss: 0.220 | Train PPL:   1.246\n",
            "\t Val. Loss: 1.350 |  Val. PPL:   3.856\n",
            "Epoch: 50 | Time: 0m 3s\n",
            "\tTrain Loss: 0.211 | Train PPL:   1.235\n",
            "\t Val. Loss: 1.422 |  Val. PPL:   4.144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_0v55Nwl2z1",
        "outputId": "da8abe73-47cb-4c00-836d-16d06ed7242c"
      },
      "source": [
        "model.load_state_dict(torch.load('tut6-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 1.370 | Test PPL:   3.937 |\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDHRoRUFlqJg"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 500):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "        \r\n",
        "    if isinstance(sentence, str):\r\n",
        "        nlp = spacy.load('en')\r\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "    else:\r\n",
        "        tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "        \r\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\r\n",
        "    \r\n",
        "    src_mask = model.make_src_mask(src_tensor)\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\r\n",
        "\r\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "    for i in range(max_len):\r\n",
        "\r\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\r\n",
        "\r\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\r\n",
        "        \r\n",
        "        with torch.no_grad():\r\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\r\n",
        "        \r\n",
        "        pred_token = output.argmax(2)[:,-1].item()\r\n",
        "        \r\n",
        "        trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "            break\r\n",
        "    \r\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "    \r\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkCYQCOlw46"
      },
      "source": [
        "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\r\n",
        "    \r\n",
        "    assert n_rows * n_cols == n_heads\r\n",
        "    \r\n",
        "    fig = plt.figure(figsize=(15,25))\r\n",
        "    \r\n",
        "    for i in range(n_heads):\r\n",
        "        \r\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i+1)\r\n",
        "        \r\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\r\n",
        "\r\n",
        "        cax = ax.matshow(_attention, cmap='bone')\r\n",
        "\r\n",
        "        ax.tick_params(labelsize=12)\r\n",
        "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \r\n",
        "                           rotation=45)\r\n",
        "        ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rwmDKUHcu8O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8009f37-b3dd-4ccf-f01c-abdde3accb25"
      },
      "source": [
        "src = 'write a python program to sum two numbers'\r\n",
        "src = Tokenize(src)\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['num1  =  1.5', 'num2  =  6.3', 'sum  =  num1 - num2', \"print ( f'sub :  {sum}' ) \", '', '', '<eos>']\n",
            "num1  =  1.5\n",
            "num2  =  6.3\n",
            "sum  =  num1 - num2\n",
            "print ( f'sub :  {sum}' ) \n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKlEna4tstVc",
        "outputId": "96599312-f3b1-41fa-be34-043b9b765b5c"
      },
      "source": [
        "src = 'write a python program to check whether the given string is palindrome'\r\n",
        "src = Tokenize(src)\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted trg = ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'else : ', '<unk>', '', '', '<eos>']\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "else : \n",
            "<unk>\n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2NlDDuML-vY",
        "outputId": "7c3b543a-fc65-45d6-85ed-a7cf2228baf9"
      },
      "source": [
        "example_idx = 0\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'function', 'to', 'check', 'if', 'a', 'given', 'string', 'is', 'a', 'palindrome']\n",
            "trg = ['', 'def ispalindrome ( s )  : ', '\\treturn s  =  =  s[ :  : -1]', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['', 'def ispalindrome ( s )  : ', '\\treturn s  =  =  s[ :  : -1]', '', '', '<eos>']\n",
            "\n",
            "def ispalindrome ( s )  : \n",
            "\treturn s  =  =  s[ :  : -1]\n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxhe4jEFMUvw",
        "outputId": "d2d4d176-b9ad-4bce-f08e-e43c0f6a3abd"
      },
      "source": [
        "example_idx = 4\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'function', 'for', 'implementation', 'of', 'insertion', 'sort']\n",
            "trg = ['', 'def insertionsort ( arr )  :  ', '', '\\tfor i in range ( 1, len ( arr )  )  :  ', '', '\\t\\tkey  =  arr[i] ', '', '\\t\\tj  =  i-1', '\\t\\twhile j > = 0 and key < arr[j]  :  ', '\\t\\t\\t\\tarr[j+1]  =  arr[j] ', '\\t\\t\\t\\tj - =  1', '\\t\\tarr[j+1]  =  key ', 'arr  =  [12, 11, 13, 5, 6] ', 'insertionsort ( arr )  ', 'print  ( f\"sorted array is :  {arr}\" )  ', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['', 'def bubblesort ( arr )  :  ', '\\tn  =  len ( arr )  ', '\\tfor i in range ( n-1 )  :  ', '\\t\\tfor j in range ( 0, n-i-1 )  :  ', '', '\\t\\t\\tif arr[j] > arr[j+1]  :  ', '\\t\\t\\t\\tarr[j], arr[j+1]  =  arr[j+1], arr[j] ', '', '<unk>', '', '<unk>', '', '<unk>', '', '<unk>', '', '<unk>', '', '<eos>']\n",
            "\n",
            "def bubblesort ( arr )  :  \n",
            "\tn  =  len ( arr )  \n",
            "\tfor i in range ( n-1 )  :  \n",
            "\t\tfor j in range ( 0, n-i-1 )  :  \n",
            "\n",
            "\t\t\tif arr[j] > arr[j+1]  :  \n",
            "\t\t\t\tarr[j], arr[j+1]  =  arr[j+1], arr[j] \n",
            "\n",
            "<unk>\n",
            "\n",
            "<unk>\n",
            "\n",
            "<unk>\n",
            "\n",
            "<unk>\n",
            "\n",
            "<unk>\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy73yM4GMdLF",
        "outputId": "859b98ba-b01f-4703-96c3-6e148881ddc3"
      },
      "source": [
        "example_idx = 13\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'function', 'to', 'generate', 'amortization', 'schedule', 'given', 'initial', 'loan', 'amount', ',', 'interest', 'rate', ',', 'annual', 'payments', 'and', 'tenure', '.']\n",
            "trg = ['import itertools', 'def loan_schedule ( principal, interest_rate, annual_payment, tenure )  : ', '\\tif ( tenure < =  0 )  : ', '\\t\\tprint ( \"invalid tenure\",tenure ) ', '\\t\\traise valueerror', '\\tif ( interest_rate > 1 or interest_rate < 0 )  : ', '\\t\\tprint ( \"invalid interest rate\",interest_rate,\" expected between 0 and 1\" ) ', '\\t\\traise valueerror', '\\tcashflows  =  [principal, *list ( itertools.repeat ( -annual_payment, tenure )  ) ]', '\\teffective_interest_rate  =  1+interest_rate', '\\treturn [ val for val in list ( itertools.accumulate ( cashflows, lambda bal, pmt :   ( bal*effective_interest_rate + pmt )  )  )  if val > 0]', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['import itertools', 'def loan_schedule ( principal, interest_rate, annual_payment, tenure )  : ', '\\tif ( tenure < =  0 )  : ', '\\t\\tprint ( \"invalid tenure\",tenure ) ', '\\t\\traise valueerror', '\\tif ( interest_rate > 1 or interest_rate < 0 )  : ', '\\t\\tprint ( \"invalid interest rate\",interest_rate,\" expected between 0 and 1\" ) ', '\\t\\traise valueerror', '\\tcashflows  =  [principal, *list ( itertools.repeat ( -annual_payment, tenure )  ) ]', '\\teffective_interest_rate  =  1+interest_rate', '\\treturn [ val for val in list ( itertools.accumulate ( cashflows, lambda bal, pmt :   ( bal*effective_interest_rate + pmt )  )  )  if val > 0]', '', '', '<eos>']\n",
            "import itertools\n",
            "def loan_schedule ( principal, interest_rate, annual_payment, tenure )  : \n",
            "\tif ( tenure < =  0 )  : \n",
            "\t\tprint ( \"invalid tenure\",tenure ) \n",
            "\t\traise valueerror\n",
            "\tif ( interest_rate > 1 or interest_rate < 0 )  : \n",
            "\t\tprint ( \"invalid interest rate\",interest_rate,\" expected between 0 and 1\" ) \n",
            "\t\traise valueerror\n",
            "\tcashflows  =  [principal, *list ( itertools.repeat ( -annual_payment, tenure )  ) ]\n",
            "\teffective_interest_rate  =  1+interest_rate\n",
            "\treturn [ val for val in list ( itertools.accumulate ( cashflows, lambda bal, pmt :   ( bal*effective_interest_rate + pmt )  )  )  if val > 0]\n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "732i-q1bMinA",
        "outputId": "733b35ca-9474-42a6-ca0a-b634843ddb96"
      },
      "source": [
        "example_idx = 18\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'function', 'that', 'returns', 'derivative', 'of', 'sine', 'value', 'of', 'the', 'input']\n",
            "trg = ['def derivative_sin ( x : float ) -> float : ', '\\timport math', '\\treturn math.cos ( x ) ', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['<unk>', '\\timport math', '\\treturn math.cos ( x ) ', '', '', '<eos>']\n",
            "<unk>\n",
            "\timport math\n",
            "\treturn math.cos ( x ) \n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RiEcnKTMmtn",
        "outputId": "7bf70f89-660c-416f-f97f-7003646996d3"
      },
      "source": [
        "example_idx = 25\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['first', 'two', 'terms']\n",
            "trg = ['n1, n2  =  0, 1', 'count  =  0', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['<unk>', '', '<eos>']\n",
            "<unk>\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yrf9IDsfMrtB",
        "outputId": "4f055cf9-2959-4d2c-9ebf-966a3983d44d"
      },
      "source": [
        "example_idx = 19\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'program', 'that', 'asks', 'user', 'to', 'guess', 'a', 'number', 'between', '1', 'and', '5', 'and', 'guess', 'it', 'within', '3', 'guesses']\n",
            "trg = ['print ( \"please guess a number between 1 and 5 and i will guess within 3 chances!\" ) ', 'guess1  =  input ( \"is it < =  3? enter y/n \\\\n\" ) ', 'if guess1  =  =  \"y\" : ', '\\tguess2  =  input ( \"is it < =  2? enter y/n \\\\n\" ) ', '\\tif guess2  =  =  \"y\" : ', '\\t\\tguess3  =  input ( \"is it 1? enter y/n \\\\n\" ) ', '\\t\\tif guess3  =  =  \"y\" : ', '\\t\\t\\tprint ( \"yay! found the number, its 1\" ) ', '\\t\\telse : ', '\\t\\t\\tprint ( \"yay! found the number, its 2\" ) ', '\\telse : ', '\\t\\tprint ( \"yay! found the number, its 3\" ) ', 'else : ', '\\tguess2  =  input ( \"is it 4? enter y/n \\\\n\" ) ', '\\tif guess2  =  =  \"y\" : ', '\\t\\tprint ( \"yay! found the number, its 4\" ) ', '\\telse : ', '\\t\\tprint ( \"yay! found the number, its 5\" ) ', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['<unk>', '<unk>', '<unk>', '\\telse : ', '<unk>', '\\tif guess2  =  =  \"y\" : ', '<unk>', '\\tif guess2  =  =  \"y\" : ', '<unk>', '\\telse : ', '<unk>', '\\tif guess2  =  =  \"y\" : ', '<unk>', '<unk>', '\\tif guess2  =  =  \"y\" : ', '<unk>', '<unk>', '<unk>', '\\telse : ', '<unk>', '', '<eos>']\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "\telse : \n",
            "<unk>\n",
            "\tif guess2  =  =  \"y\" : \n",
            "<unk>\n",
            "\tif guess2  =  =  \"y\" : \n",
            "<unk>\n",
            "\telse : \n",
            "<unk>\n",
            "\tif guess2  =  =  \"y\" : \n",
            "<unk>\n",
            "<unk>\n",
            "\tif guess2  =  =  \"y\" : \n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "\telse : \n",
            "<unk>\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7OZC9cBNN0I",
        "outputId": "df77d87d-b47a-4660-a721-471161d6b10f"
      },
      "source": [
        "example_idx = 31\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['python', 'program', 'to', 'find', 'largest', 'and', 'smallest', 'number', 'in', 'a', 'list']\n",
            "trg = ['', 'numlist  =  []', 'number  =  int ( input ( \"please enter the total number of list elements :  \" )  ) ', 'for i in range ( 1, number + 1 )  : ', '\\tvalue  =  int ( input ( \"please enter the value of %d element  :  \" %i )  ) ', '\\tnumlist.append ( value ) ', '', 'smallest  =  largest  =  numlist[0]', '', 'for j in range ( 1, number )  : ', '\\tif ( smallest > numlist[j] )  : ', '\\t\\tsmallest  =  numlist[j]', '\\t\\tmin_position  =  j', '\\tif ( largest < numlist[j] )  : ', '\\t\\tlargest  =  numlist[j]', '\\t\\tmax_position  =  j', '', 'print ( \"the smallest element in this list is  :  \", smallest ) ', 'print ( \"the index position of smallest element in this list is  :  \", min_position ) ', 'print ( \"the largest element in this list is  :  \", largest ) ', 'print ( \"the index position of largest element in this list is  :  \", max_position ) ', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdpFkYGLNQvs",
        "outputId": "29d922e8-f736-4bd1-b635-2a5af405577c"
      },
      "source": [
        "example_idx = 6\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'program', 'that', 'prints', 'the', 'number', 'of', 'unique', 'keys', 'in', 'a', 'list', 'of', 'dictionaries', '.']\n",
            "trg = ['list_of_dicts  =  [{\"key1\" :  \"val1\", \"country\" :  \"india\"}, ', '\\t\\t\\t\\t {\"country\" :  \"usa\", \"foo\" :  \"bar\"},', '\\t\\t\\t\\t {\"foo\" :  \"bar\", \"foo2\" : \"bar2\"}]', 'unique_keys  =  []', 'for d in list_of_dicts : ', '  for key in d : ', '\\tif key not in unique_keys : ', '\\t  unique_keys.append ( key ) ', 'print ( f\"number of unique keys :  {len ( unique_keys ) }\" ) ', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['list_of_dicts  =  [{\"key1\" :  \"val1\", \"country\" :  \"india\"}, ', '\\t\\t\\t\\t {\"country\" :  \"usa\", \"foo\" :  \"bar\"},', '\\t\\t\\t\\t {\"foo\" :  \"bar\", \"foo2\" : \"bar2\"}]', 'unique_keys  =  []', 'for d in list_of_dicts : ', '  for key in d : ', '\\tif key not in unique_keys : ', '\\t  unique_keys.append ( key ) ', 'print ( f\"number of unique keys :  {len ( unique_keys ) }\" ) ', '', '', '<eos>']\n",
            "list_of_dicts  =  [{\"key1\" :  \"val1\", \"country\" :  \"india\"}, \n",
            "\t\t\t\t {\"country\" :  \"usa\", \"foo\" :  \"bar\"},\n",
            "\t\t\t\t {\"foo\" :  \"bar\", \"foo2\" : \"bar2\"}]\n",
            "unique_keys  =  []\n",
            "for d in list_of_dicts : \n",
            "  for key in d : \n",
            "\tif key not in unique_keys : \n",
            "\t  unique_keys.append ( key ) \n",
            "print ( f\"number of unique keys :  {len ( unique_keys ) }\" ) \n",
            "\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfdyH-3uNUhT",
        "outputId": "feb6c3a2-bb93-4ba3-f255-d5e2c28045fd"
      },
      "source": [
        "example_idx = 22\r\n",
        "\r\n",
        "src = vars(val.examples[example_idx])['Title']\r\n",
        "trg = vars(val.examples[example_idx])['Target_code']\r\n",
        "\r\n",
        "print(f'src = {src}')\r\n",
        "print(f'trg = {trg}')\r\n",
        "\r\n",
        "translation, attention = translate_sentence(src, SRC, TRG, model, device)\r\n",
        "print('\\n\\n')\r\n",
        "print(f'predicted trg = {translation}')\r\n",
        "for word in translation:\r\n",
        "  print(word)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src = ['write', 'a', 'python', 'program', ' ', 'to', 'convert', 'list', 'of', 'tuples', 'into', 'list']\n",
            "trg = ['', \"lt  =  [ ( 'english', 2 ) ,  ( 'maths', 4 ) ,  ( 'science', '6' ) ] \", 'out  =  [item for t in lt for item in t]  ', 'print ( out ) ', '', '']\n",
            "\n",
            "\n",
            "\n",
            "predicted trg = ['<unk>', '<unk>', '<unk>', '', '<eos>']\n",
            "<unk>\n",
            "<unk>\n",
            "<unk>\n",
            "\n",
            "<eos>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}